{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize data, load packages and needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seeds = [42, 100, 0, 10, 12, 20, 50, 9, 30, 51]\n",
    "run = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'meganorm-yverduyn'\n",
    "datasets = {\n",
    "    'TDBrain': {''\n",
    "        'base_dir': '/project/meganorm/Data/EEG_TDBrain/EEG/', #Final\n",
    "        #'base_dir': '/home/meganorm-yverduyn/Dev/BIDS_TDBrain',  #To test \n",
    "        'task': 'task-restEC', \n",
    "        'ending': 'eeg.vhdr'\n",
    "    },\n",
    "\n",
    "    'MIPDB': {\n",
    "        'base_dir': '/project/meganorm/Data/EEG_MIPDB/EEG_BIDS/', #Final\n",
    "        #'base_dir': '/home/meganorm-yverduyn/Dev/MIPDB/EEG_BIDS',  #To test \n",
    "        'task': 'task-eyesclosed', \n",
    "        'ending': 'eeg.set'\n",
    "},\n",
    "\n",
    "    'CMI': {\n",
    "        'base_dir': '/project/meganorm/Data/EEG_CMI/EEG_BIDS', #Final\n",
    "        #'base_dir': '/home/meganorm-yverduyn/Dev/BIDS_CMI',  #To test \n",
    "        'task': 'task-eyesclosed', \n",
    "        'ending': 'eeg.set'\n",
    "    }\n",
    "    }\n",
    "\n",
    "package_path = f'/home/{username}/Code/MEGaNorm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(package_path)\n",
    "from utils.parallel import submit_jobs, check_jobs_status, collect_results\n",
    "from utils.nm import hbr_data_split, estimate_centiles\n",
    "from plots.plots import plot_nm_range_site2, plot_age_dist2, box_plot_auc\n",
    "from utils.nm import prepare_prediction_data\n",
    "from utils.IO import merge_fidp_demo, merge_datasets_with_glob\n",
    "from datasets.mne_bids_conversion import make_demo_file_bids\n",
    "import pandas as pd\n",
    "import json\n",
    "from pcntoolkit.normative_parallel import execute_nm\n",
    "import warnings\n",
    "import numpy as np\n",
    "from pcntoolkit.util.utils import z_to_abnormal_p, anomaly_detection_auc\n",
    "from scipy.stats import false_discovery_control\n",
    "import pickle \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_config(project, path=None):\n",
    "\n",
    "    # preprocess configurations =================================================\n",
    "    # downsample data\n",
    "    config = dict()\n",
    "\n",
    "    # You could also set layout to None to have high \n",
    "    # choices: all, lobe, None\n",
    "    config[\"which_layout\"] = \"all\"\n",
    "\n",
    "    # which sensor type should be used\n",
    "    # choices: meg, mag, grad, eeg, opm\n",
    "    config[\"which_sensor\"] = \"eeg\"\n",
    "    # config['fs'] = 500\n",
    "\n",
    "    # ICA configuration\n",
    "    config['ica_n_component'] = 25\n",
    "    config['ica_max_iter'] = 800\n",
    "    config['ica_method'] = \"infomax\" \n",
    "\n",
    "    # lower and upper cutoff frequencies in a bandpass filter\n",
    "    config['cutoffFreqLow'] = 1\n",
    "    config['cutoffFreqHigh'] = 45\n",
    "\n",
    "    config[\"resampling_rate\"] = 1000\n",
    "    config[\"digital_filter\"] = True\n",
    "    config[\"notch_filter\"] = False\n",
    "\n",
    "    config[\"apply_ica\"] = True\n",
    "\n",
    "    config[\"auto_ica_corr_thr\"] = 0.8\n",
    "\n",
    "    config[\"rereference_method\"]= \"average\"\n",
    "    \n",
    "    # variance threshold across time\n",
    "    config[\"mag_var_threshold\"] = 4e-12\n",
    "    config[\"grad_var_threshold\"] = 4000e-13\n",
    "    config[\"eeg_var_threshold\"] = 40e-6  \n",
    "    # flatness threshold across time\n",
    "    config[\"mag_flat_threshold\"] = 10e-15\n",
    "    config[\"grad_flat_threshold\"] = 10e-15\n",
    "    config[\"eeg_flat_threshold\"] = 10e-6 \n",
    "\n",
    "    # segmentation ==============================================\n",
    "    #start time of the raw data to use in seconds, this is to avoid possible eye blinks in close-eyed resting state. \n",
    "    config['segments_tmin'] = 5\n",
    "    # end time of the raw data to use in seconds, this is to avoid possible eye blinks in close-eyed resting state.\n",
    "    config['segments_tmax'] = -5\n",
    "    # length of EEG segments in seconds\n",
    "    config['segments_length'] = 10\n",
    "    # amount of overlap between EEG sigals in seconds\n",
    "    config['segments_overlap'] = 2\n",
    "\n",
    "    # PSD ==============================================\n",
    "    # Spectral estimation method\n",
    "    config['psd_method'] = \"welch\"\n",
    "    # amount of overlap between windows in Welch's method\n",
    "    config['psd_n_overlap'] = 1\n",
    "    config['psd_n_fft'] = 2\n",
    "    # number of samples in psd\n",
    "    config[\"psd_n_per_seg\"] = 2\n",
    "\n",
    "    # fooof analysis configurations ==============================================\n",
    "    # Desired frequency range to run FOOOF\n",
    "    config['fooof_freqRangeLow'] = 3\n",
    "    config['fooof_freqRangeHigh'] = 40\n",
    "    # which mode should be used for fitting; choices (knee, fixed)\n",
    "    config[\"aperiodic_mode\"] = \"knee\"\n",
    "    # minimum acceptable peak width in fooof analysis\n",
    "    config[\"fooof_peak_width_limits\"] = [1.0, 12.0]\n",
    "    #Absolute threshold for detecting peaks\n",
    "    config['fooof_min_peak_height'] = 0\n",
    "    #Relative threshold for detecting peaks\n",
    "    config['fooof_peak_threshold'] = 2\n",
    "\n",
    "    # feature extraction ==========================================================\n",
    "    # Define frequency bands\n",
    "    config['freq_bands'] = {\n",
    "                            'Theta': (3, 8),\n",
    "                            'Alpha': (8, 13),\n",
    "                            'Beta': (13, 30),\n",
    "                            'Gamma': (30, 40),\n",
    "                            # 'Broadband': (3, 40)\n",
    "                            }\n",
    "\n",
    "    # Define individualized frequency range over main peaks in each freq band\n",
    "    config['individualized_band_ranges'] = { \n",
    "                                            'Theta': (-2, 3),\n",
    "                                            'Alpha': (-2, 3), # change to (-4,2)\n",
    "                                            'Beta': (-8, 9),\n",
    "                                            'Gamma': (-5, 5)\n",
    "                                            }\n",
    "\n",
    "    # least acceptable R squred of fitted models\n",
    "    config['min_r_squared'] = 0.9 \n",
    " \n",
    "    config['feature_categories'] = {\n",
    "                                    \"Offset\":False,\n",
    "                                    \"Exponent\":False,\n",
    "                                    \"Peak_Center\":True,\n",
    "                                    \"Peak_Power\":True,\n",
    "                                    \"Peak_Width\":True,\n",
    "                                    \"Adjusted_Canonical_Relative_Power\":True, \n",
    "                                    \"Adjusted_Canonical_Absolute_Power\":False,\n",
    "                                    \"Adjusted_Individualized_Relative_Power\":False,\n",
    "                                    \"Adjusted_Individualized_Absolute_Power\":False,\n",
    "                                    \"OriginalPSD_Canonical_Relative_Power\":True, \n",
    "                                    \"OriginalPSD_Canonical_Absolute_Power\":False,\n",
    "                                    \"OriginalPSD_Individualized_Relative_Power\":False,\n",
    "                                    \"OriginalPSD_Individualized_Absolute_Power\":False,\n",
    "                                    }\n",
    "    \n",
    "    config[\"fooof_res_save_path\"] = None\n",
    "\n",
    "    config[\"random_state\"] = 97#change? \n",
    "\n",
    "    if path is not None:\n",
    "        out_file = open(os.path.join(path, project + \".json\"), \"w\") \n",
    "        json.dump(config, out_file, indent = 6) \n",
    "        out_file.close()\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define directories and job specifications needed for feature extraction and NM, merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"Thesis\"\n",
    "\n",
    "project_dir = f'/home/{username}/Results/{project}/'\n",
    "\n",
    "mainParallel_path = os.path.join(package_path, 'src', 'mainParallel.py')\n",
    "\n",
    "features_dir = os.path.join(project_dir, 'Features')\n",
    "features_log_path = os.path.join(features_dir, 'log')\n",
    "features_temp_path = os.path.join(features_dir,'temp')\n",
    "\n",
    "nm_processing_dir = os.path.join(project_dir, 'NM', 'Run_' + str(run))\n",
    "\n",
    "job_configs = {'log_path':features_log_path, 'module':'mne', 'time':'1:00:00', 'memory':'20GB', \n",
    "                'partition':'normal', 'core':1, 'node':1, 'batch_file_name':'batch_job'}\n",
    "\n",
    "if not os.path.isdir(features_log_path):\n",
    "    os.makedirs(features_log_path)\n",
    "\n",
    "if not os.path.isdir(features_temp_path):\n",
    "    os.makedirs(features_temp_path)\n",
    "    \n",
    "if not os.path.isdir(nm_processing_dir):\n",
    "    os.makedirs(nm_processing_dir)\n",
    "    \n",
    "configs = make_config(project, project_dir)\n",
    "\n",
    "subjects = merge_datasets_with_glob(datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f-IDPs Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parallel feature extraction  \n",
    "\n",
    "# # Running Jobs\n",
    "start_time = submit_jobs(mainParallel_path, features_dir, subjects, \n",
    "                features_temp_path, job_configs=job_configs, config_file=os.path.join(project_dir, project+'.json'))\n",
    "# Checking jobs\n",
    "failed_jobs = check_jobs_status(username, start_time)\n",
    "\n",
    "falied_subjects = {failed_job:subjects[failed_job] for failed_job in failed_jobs}\n",
    "\n",
    "while len(failed_jobs)>0:\n",
    "    # Re-running Jobs\n",
    "    start_time = submit_jobs(mainParallel_path, features_dir, falied_subjects, \n",
    "                features_temp_path, job_configs=job_configs, config_file=os.path.join(project_dir, project+'.json'))\n",
    "    # Checking jobs\n",
    "    failed_jobs = check_jobs_status(username, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_results(features_dir, subjects, features_temp_path, file_name='all_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create covariate files, merge covariates and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create participants.tsv \n",
    "file_dir1 =  \"/project/meganorm/Data/EEG_CMI/EEG_BIDS/participants_Mod.tsv\"\n",
    "save_dir1 = \"/project/meganorm/Data/EEG_CMI/EEG_BIDS/participants_bids.tsv\"\n",
    "make_demo_file_bids(file_dir1, \n",
    "                        save_dir1, \n",
    "                        0, \n",
    "                        2, \n",
    "                        {\"col_name\": \"sex\", \"col_id\": 1, \"mapping\":{0: \"Male\", 1: \"Female\"}, \"single_value\":None}, \n",
    "                        {\"col_name\": \"site\", \"col_id\": 6, \"mapping\":{\"CMI1\": \"CMI1\", \"CMI2\": \"CMI2\", \"CMI3\": \"CMI3\", \"CMI4\": \"CMI4\", \"CMI5\": \"CMI5\"}, \"single_value\":None},\n",
    "                        {\"col_name\": \"eyes\", \"col_id\": None, \"mapping\": None, \"single_value\":\"eyes_closed\"},\n",
    "                        {\"col_name\": \"diagnosis\", \"col_id\": 10, \"mapping\": {\n",
    "                            \"Attention-Deficit/Hyperactivity Disorder\": \"adhd\",\n",
    "                            \"Specific Learning Disorder\": \"specific learning disorder\", \n",
    "                            \"Schizophrenia Spectrum and other Psychotic Disorders\": \"schizophrenia spectrum and other psychotic disorder\", \n",
    "                            \"Nonadherence to Medical Treatment\": \"nonadherence to medical treatment\", \n",
    "                            \"Autism Spectrum Disorder\": \"asd\",\n",
    "                            \"Gender Dysphoria\": \"gender dysphoria\", \n",
    "                            \"No Diagnosis Given: Incomplete Eval\": \"unknown\",\n",
    "                            \"Obsessive Compulsive and Related Disorders\": \"obsessive compulsive and related disorder\",\n",
    "                            \"Elimination Disorders\": \"elimination disorder\",\n",
    "                            \"Bipolar and Related Disorders\": \"bipolar and related disorder\",\n",
    "                            \"Disruptive, Impulse Control and Conduct Disorders\": \"disruptive, impulse control and conduct disorder\",\n",
    "                            \"Anxiety Disorders\": \"anxiety disorder\",\n",
    "                            \"No Diagnosis Given\": \"control\", \n",
    "                            \"Neurocognitive Disorders\": \"neurocognitive disorder\", \n",
    "                            \"Depressive Disorders\": \"depressive disorder\", \n",
    "                            \"Feeding and Eating Disorders\": \"feeding and eating disorder\", \n",
    "                            \"Trauma and Stressor Related Disorders\": \"trauma and stressor related disorder\", \n",
    "                            \"nan\": \"unknown\", \"Communication Disorder\": \"communication disorder\", \n",
    "                            \"Intellectual Disability\": \"intellectual disability\",\n",
    "                            \"Motor Disorder\": \"motor disorder\", \n",
    "                            \"Cannabis-Related\": \"cannabis-related\", \n",
    "                            \"Other Neurodevelopmental Disorders\": \"other neurodevelopmental disorder\"}, \"single_value\":None})\n",
    "\n",
    "file_dir2 = \"/project/meganorm/Data/EEG_TDBrain/EEG/TDBRAIN_participants_V2.tsv\"\n",
    "save_dir2 = \"/project/meganorm/Data/EEG_TDBrain/EEG/participants_bids.tsv\"\n",
    "make_demo_file_bids(file_dir2, \n",
    "                        save_dir2, \n",
    "                        0, \n",
    "                        10, \n",
    "                        {\"col_name\": \"sex\", \"col_id\": 11, \"mapping\": {1.0: \"Male\", 0.0: \"Female\"}, \"single_value\":None},\n",
    "                        {\"col_name\": \"eyes\", \"col_id\": None, \"mapping\": None, \"single_value\":\"eyes_closed\"},\n",
    "                        {\"col_name\": \"diagnosis\", \"col_id\": 3, \"mapping\": {\n",
    "                            \"UNKNOWN\": \"unknown\", \n",
    "                            \"REPLICATION\": \"replication\", \"BURNOUT\": \"burnout\",  \"SMC\": \"smc\", \n",
    "                            \"HEALTHY\": \"control\", \"Dyslexia\": \"dyslexia\", \"CHRONIC PAIN\": \"chronic pain\", \n",
    "                            \"MDD\": \"mdd\", \"nan\": \"nan\", \"ADHD\": \"adhd\", \n",
    "                            \"ADHD/ASPERGER\": \"adhd/asperger\", \"PDD NOS/DYSLEXIA\": \"pdd nos/dyslexia\", \n",
    "                            \"PDD NOS\": \"pdd nos\", \"WHIPLASH\": \"whiplash\", \"ANXIETY\": \"anxiety\",\n",
    "                            \"ADHD/DYSLEXIA\": \"adhd/dyslexia\", \"ASD\": \"asd\", \"TINNITUS\": \"tinnitus\",\n",
    "                            \"OCD\": \"ocd\", \"Tinnitus\": \"tinnitus\", \"PDD NOS \": \"pdd nos\", \"PANIC\": \"panic\",\n",
    "                            \"MDD/ANXIETY\": \"mdd/anxiety\", \"MIGRAINE\": \"migraine\", \"PDD NOS/ANXIETY\": \"pdd nos/anxiety\",\n",
    "                            \"PARKINSON\": \"parkinson\",  \"BIPOLAR\": \"bipolar\",  \"MDD/bipolar\": \"mdd/bipolar\",\n",
    "                            \"DYSPRAXIA\": \"dyspraxia\", \"TINNITUS/MDD\": \"tinnitus/mdd\", \"ADHD/ASD/ANXIETY\": \"adhd/asd/anxiety\",\n",
    "                            \"MDD/ADHD\": \"mdd/adhd\",  \"ADHD/PDD NOS\": \"adhd/pdd nos\", \"MDD/BIPOLAR\": \"mdd/bipolar\",\n",
    "                            \"ASPERGER\": \"asperger\", \"ADHD/EPILEPSY\": \"adhd/epilepsy\", \"MDD/PAIN\": \"mdd/pain\",\n",
    "                            \"PDD NOS/GTS\": \"pdd nos/gts\",  \"PDD NOS/ADHD\": \"pdd nos/adhd\", \"PDD NOS/ASD\": \"pdd nos/asd\",\n",
    "                            \"TBI\": \"tbi\", \"ADHD/ANXIETY\": \"adhd/anxiety\",  \"ADHD/DYSLEXIA/DYSCALCULIA\": \"adhd/dyslexia/dyscalculia\",\n",
    "                            \"ADHD/MDD\": \"adhd/mdd\", \"MDD/PANIC\": \"mdd/panic\", \"DEPERSONALIZATION\": \"depersonalization\",\n",
    "                            \"MDD/TRAUMA\": \"mdd/trauma\", \"PTSD/ADHD\": \"ptsd/adhd\",  \"OCD/DPS\": \"ocd/dps\",\"MDD/OCD\": \"mdd/ocd\",\n",
    "                            \"MDD/TUMOR\": \"mdd/tumor\", \"ADHD/GTS\": \"adhd/gts\", \"OCD/MDD\": \"ocd/mdd\", \"CONVERSION DX\": \"conversion dx\",\n",
    "                            \"ASD/ASPERGER\": \"asd/asperger\", \"MDD/ADHD/LYME\": \"mdd/adhd/lyme\", \"ADHD/OCD\": \"adhd/ocd\",\n",
    "                            \"MSA-C\": \"msa-c\", \"OCD/ASD\": \"ocd/asd\", \"STROKE/PAIN\": \"stroke/pain\",\n",
    "                            \"STROKE \": \"stroke\", \"MDD/OCD/ADHD\": \"mdd/ocd/adhd\",  \"EPILEPSY/OCD\": \"epilepsy/ocd\",\n",
    "                            \"ADHD \": \"adhd\", \"INSOMNIA\": \"insomnia\", \"MDD/ADHD/ANOREXIA\": \"mdd/adhd/anorexia\",\n",
    "                            \"MDD/ANXIETY/TINNITUS\": \"mdd/anxiety/tinnitus\"}, \"single_value\":None})\n",
    "\n",
    "\n",
    "file_dir3 = \"/project/meganorm/Data/EEG_MIPDB/info/MIPDB_PublicFile.csv\"\n",
    "save_dir3 = \"/project/meganorm/Data/EEG_MIPDB/EEG_BIDS/participants_bids.tsv\"\n",
    "make_demo_file_bids(file_dir3, \n",
    "                    save_dir3, \n",
    "                    0, \n",
    "                    1, \n",
    "                    {\"col_name\": \"sex\", \"col_id\": 2, \"mapping\": {1.0: \"Male\", 2.0: \"Female\"}, \"single_value\":None},\n",
    "                    {\"col_name\": \"eyes\", \"col_id\": None, \"mapping\": None, \"single_value\":\"eyes_closed\"},\n",
    "                    {\"col_name\": \"diagnosis\", \"col_id\": 37, \"mapping\": {\n",
    "                        0: \"control\",\n",
    "                        1: \"unknown_1\",\n",
    "                        2: \"unknown_2\"}, \"single_value\":None})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preparation for Normative Modeling\n",
    "base_dirs = [values[\"base_dir\"] for values in datasets.values()]\n",
    "dataset_names = list(datasets.keys())\n",
    "\n",
    "\"\"\" ADHD_diagnosis = [\n",
    "    \"adhd combined type\",\n",
    "    \"adhd inattentive type\",\n",
    "    \"adhd hyperactive impulsive type\",\n",
    "    \"other specified attention deficit hyperactivity disorder\",\n",
    "    \"unspecified attention deficit hyperactivity disorder\",\n",
    "    \"adhd\",\n",
    "    \"adhd/asperger\",\n",
    "    \"adhd/dyslexia\",\n",
    "    \"adhd/asd/anxiety\",\n",
    "    \"mdd/adhd\", \n",
    "    \"adhd/pdd nos\",\n",
    "    \"pdd nos/adhd\", \n",
    "    \"adhd/epilepsy\",\n",
    "    \"adhd/anxiety\",\n",
    "    \"adhd/dyslexia/dyscalculia\",\n",
    "    \"adhd/mdd\",\n",
    "    \"mdd/adhd/lyme\", \n",
    "    \"ptsd/adhd\",\n",
    "    \"adhd/gts\",\n",
    "    \"adhd/ocd\",\n",
    "    \"mdd/ocd/adhd\", \n",
    "    \"mdd/adhd/anorexia\"\n",
    "]\n",
    "\"\"\"\n",
    "all_diagnosis = ['adhd', 'specific learning disorder', 'nonadherence to medical treatment', 'asd', 'anxiety disorder', 'communication disorder', \n",
    "                 'intellectual disability', 'depressive disorder', 'motor disorder', 'feeding and eating disorder', 'trauma and stressor related disorder', \n",
    "                 'disruptive, impulse control and conduct disorder', 'elimination disorder', 'bipolar and related disorder', 'obsessive compulsive and related disorder', \n",
    "                 'cannabis-related', 'neurocognitive disorder', 'unknown', 'schizophrenia spectrum and other psychotic disorder', 'other neurodevelopmental disorder', 'gender dysphoria', \n",
    "                 'nan', 'replication', 'burnout', 'unknown','dyslexia', 'chronic pain', 'mdd', 'ocd', 'adhd', 'parkinson', 'insomnia', 'unknown_1', 'unknown_2']\n",
    "\n",
    "merged_data, data_patient = merge_fidp_demo(base_dirs, features_dir, dataset_names, include_patients=True, diagnosis = all_diagnosis)\n",
    "merged_data = merged_data.drop(index=\"sub-NDARAA075AMK\")\n",
    "biomarker_num = hbr_data_split(merged_data, nm_processing_dir, drop_nans=True, batch_effects=['sex', 'site'], random_seed=random_seeds[run], train_split=0.50)\n",
    "print(biomarker_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site =0\n",
    "print(\"Dataset name: TDBrain\")\n",
    "print(\"size: \", merged_data[merged_data.site==site].shape[0], \"participants\")\n",
    "print(\"Number of controls:\", merged_data[(merged_data[\"site\"] == site) & (merged_data[\"diagnosis\"] == 0)].shape[0])\n",
    "print(\"mean age: \", merged_data[merged_data.site==site][\"age\"].mean())\n",
    "print(\"std age: \", merged_data[merged_data.site==site][\"age\"].std())\n",
    "print(\"female num: \", merged_data[np.logical_and(merged_data.site==site, merged_data.sex==1)].shape[0], \"participants\")\n",
    "\n",
    "site =1\n",
    "print(\"Dataset name: MIPDB\")\n",
    "print(\"size: \", merged_data[merged_data.site==site].shape[0], \"participants\")\n",
    "print(\"Number of controls:\", merged_data[(merged_data[\"site\"] == site) & (merged_data[\"diagnosis\"] == 0)].shape[0])\n",
    "print(\"mean age: \", merged_data[merged_data.site==site][\"age\"].mean())\n",
    "print(\"std age: \", merged_data[merged_data.site==site][\"age\"].std())\n",
    "print(\"female num: \", merged_data[np.logical_and(merged_data.site==site, merged_data.sex==1)].shape[0], \"participants\")\n",
    "\n",
    "site =2\n",
    "print(\"Dataset name: CMI1\")\n",
    "print(\"size: \", merged_data[merged_data.site==site].shape[0], \"participants\")\n",
    "print(\"Number of controls:\", merged_data[(merged_data[\"site\"] == site) & (merged_data[\"diagnosis\"] == 0)].shape[0])\n",
    "print(\"mean age: \", merged_data[merged_data.site==site][\"age\"].mean())\n",
    "print(\"std age: \", merged_data[merged_data.site==site][\"age\"].std())\n",
    "print(\"female num: \", merged_data[np.logical_and(merged_data.site==site, merged_data.sex==1)].shape[0], \"participants\")\n",
    "\n",
    "site =3\n",
    "print(\"Dataset name: CMI2\")\n",
    "print(\"size: \", merged_data[merged_data.site==site].shape[0], \"participants\")\n",
    "print(\"Number of controls:\", merged_data[(merged_data[\"site\"] == site) & (merged_data[\"diagnosis\"] == 0)].shape[0])\n",
    "print(\"mean age: \", merged_data[merged_data.site==site][\"age\"].mean())\n",
    "print(\"std age: \", merged_data[merged_data.site==site][\"age\"].std())\n",
    "print(\"female num: \", merged_data[np.logical_and(merged_data.site==site, merged_data.sex==1)].shape[0], \"participants\")\n",
    "\n",
    "site =4\n",
    "print(\"Dataset name: CMI3\")\n",
    "print(\"size: \", merged_data[merged_data.site==site].shape[0], \"participants\")\n",
    "print(\"Number of controls:\", merged_data[(merged_data[\"site\"] == site) & (merged_data[\"diagnosis\"] == 0)].shape[0])\n",
    "print(\"mean age: \", merged_data[merged_data.site==site][\"age\"].mean())\n",
    "print(\"std age: \", merged_data[merged_data.site==site][\"age\"].std())\n",
    "print(\"female num: \", merged_data[np.logical_and(merged_data.site==site, merged_data.sex==1)].shape[0], \"participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the confgurations and job specifications for NM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting up NM configs\n",
    "\n",
    "python_path = '/project/meganorm/Software/Miniconda3/envs/mne/bin/python' \n",
    "\n",
    "hbr_configs = {\n",
    "                'homo_Gaussian_linear':{'model_type':'linear', 'likelihood':'Normal', 'linear_sigma':'False',\n",
    "                                        'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                'homo_Gaussian_bspline':{'model_type':'bspline', 'likelihood':'Normal', 'linear_sigma':'False',\n",
    "                                        'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                'homo_SHASH_linear':{'model_type':'linear', 'likelihood':'SHASHb', 'linear_sigma':'False',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                'homo_SHASH_bspline':{'model_type':'bspline', 'likelihood':'SHASHb', 'linear_sigma':'False',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                'hetero_Gaussian_linear':{'model_type':'linear', 'likelihood':'Normal', 'linear_sigma':'True',\n",
    "                                        'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'},\n",
    "                'hetero_Gaussian_bspline':{'model_type':'bspline', 'likelihood':'Normal', 'linear_sigma':'True',\n",
    "                                        'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'},\n",
    "                'hetero_SHASH_linear':{'model_type':'linear', 'likelihood':'SHASHb', 'linear_sigma':'True',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'True', 'linear_delta':'True'},\n",
    "                'hetero_SHASH_bspline':{'model_type':'bspline', 'likelihood':'SHASHb', 'linear_sigma':'True',\n",
    "                                        'random_slope_mu':'False', 'linear_epsilon':'True', 'linear_delta':'True'},\n",
    "            }\n",
    "\n",
    "inscaler='None' \n",
    "outscaler='None' \n",
    "batch_size = 1\n",
    "outputsuffix = '_estimate'\n",
    "\n",
    "respfile = os.path.join(nm_processing_dir, 'y_train.pkl')\n",
    "covfile = os.path.join(nm_processing_dir, 'x_train.pkl')\n",
    "\n",
    "testrespfile_path = os.path.join(nm_processing_dir, 'y_test.pkl')\n",
    "testcovfile_path = os.path.join(nm_processing_dir, 'x_test.pkl')\n",
    "\n",
    "trbefile = os.path.join(nm_processing_dir, 'b_train.pkl')\n",
    "tsbefile = os.path.join(nm_processing_dir, 'b_test.pkl')\n",
    "\n",
    "memory = '2gb'\n",
    "duration = '5:00:00'\n",
    "cluster_spec = 'slurm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the normative modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for method in hbr_configs.keys():\n",
    "method = 'hetero_SHASH_bspline'\n",
    "processing_dir = os.path.join(nm_processing_dir, method) + '/'\n",
    "nm_log_path = os.path.join(processing_dir, 'log') + '/'\n",
    "\n",
    "if not os.path.isdir(processing_dir):\n",
    "    os.makedirs(processing_dir)\n",
    "if not os.path.isdir(nm_log_path):\n",
    "    os.makedirs(nm_log_path)\n",
    "\n",
    "execute_nm(processing_dir, python_path,\n",
    "            'NM', covfile, respfile, batch_size, memory, duration, alg='hbr', \n",
    "            log_path=nm_log_path, binary=True, testcovfile_path=testcovfile_path, \n",
    "            testrespfile_path=testrespfile_path,trbefile=trbefile, tsbefile=tsbefile, \n",
    "            model_type=hbr_configs[method]['model_type'], likelihood=hbr_configs[method]['likelihood'],  \n",
    "            linear_sigma=hbr_configs[method]['linear_sigma'], random_slope_mu=hbr_configs[method]['random_slope_mu'],\n",
    "            linear_epsilon=hbr_configs[method]['linear_epsilon'], linear_delta=hbr_configs[method]['linear_delta'], \n",
    "            savemodel='True', inscaler=inscaler, outscaler=outscaler, outputsuffix=outputsuffix, \n",
    "            interactive='auto', cluster_spec=cluster_spec, nuts_sampler=\"nutpie\", n_cores_per_batch=\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate the centiles and plot them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimate centiles \n",
    "method = 'hetero_SHASH_bspline'\n",
    "processing_path = os.path.join(nm_processing_dir, method)\n",
    "biomarker_num = 20\n",
    "\n",
    "q = estimate_centiles(processing_path, biomarker_num, quantiles=[0.05, 0.25, 0.5, 0.75, 0.95],\n",
    "                          batch_map={0:{'Male':0, 'Female':1}, 1:{'TDBrain':0, 'MIPDB':1, 'CMI1':2, 'CMI2':3, 'CMI3': 4}}, \n",
    "                          age_range=[5, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot ranges \n",
    "method = 'hetero_SHASH_bspline'\n",
    "processing_path = os.path.join(nm_processing_dir, method)\n",
    "\n",
    "plot_nm_range_site2(processing_path, nm_processing_dir, batch_marker={\"site\":['TDBrain', 'MIPDB', 'CMI1', 'CMI2', 'CMI3']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot age distribution for different sites and train/test/validation partitions\n",
    "path = \"/home/meganorm-yverduyn/Dev\"\n",
    "plot_age_dist2(merged_data, site_names=list(datasets.keys()), save_path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute evaluation metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MACE\n",
    "from utils.nm import evaluate_mace\n",
    "model_path = \"/home/meganorm-yverduyn/Results/CMI/NM/Run_0/hetero_SHASH_bspline/Models\"\n",
    "X_path = \"/home/meganorm-yverduyn/Results/CMI/NM/Run_0/x_test.pkl\"\n",
    "y_path = \"/home/meganorm-yverduyn/Results/CMI/NM/Run_0/y_test.pkl\"\n",
    "be_path = \"/home/meganorm-yverduyn/Results/CMI/NM/Run_0/b_test.pkl\"\n",
    "\n",
    "# Initialize a list to store results\n",
    "mace_results = []\n",
    "\n",
    "# Loop through model IDs 1 to 20\n",
    "for model_id in range(0, 20):\n",
    "    # Call the evaluate_mace function\n",
    "    mace_result = evaluate_mace(\n",
    "        model_path=model_path,\n",
    "        X_path=X_path,\n",
    "        y_path=y_path,\n",
    "        be_path=be_path,\n",
    "        model_id=model_id,\n",
    "        quantiles=[0.05, 0.25, 0.5, 0.75, 0.95],\n",
    "        plot=False,\n",
    "        outputsuffix='estimate'\n",
    "    )\n",
    "    mace_results.append((model_id, mace_result))\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Model {model_id}: MACE = {mace_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAPIRO\n",
    "import pickle\n",
    "file_path = \"/home/meganorm-yverduyn/Results/CMI/NM/Run_0/hetero_SHASH_bspline/Z_estimate.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    z_scores = pickle.load(file)\n",
    "\n",
    "print(z_scores)\n",
    "covariates_path = \"/home/meganorm-yverduyn/Results/CMI/NM/Run_0/x_test.pkl\"\n",
    "with open(covariates_path, 'rb') as file:\n",
    "    covariates = pickle.load(file)\n",
    "\n",
    "from utils.nm import shapiro_stat\n",
    "shapiro_stat(z_scores, covariates, n_bins=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLINICAL VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seeds = [0]\n",
    "method = 'hetero_SHASH_bspline'\n",
    "processing_dir = os.path.join(nm_processing_dir, method) + '/'\n",
    "nm_log_path = os.path.join(processing_dir, 'log') + '/'\n",
    "\n",
    "for i in range(len(random_seeds)):\n",
    "\n",
    "    nm_processing_dir_temp = nm_processing_dir.replace(\"Run_0\", f\"Run_{i}\")\n",
    "    processing_dir_temp = processing_dir.replace(\"Run_0\", f\"Run_{i}\")\n",
    "\n",
    "    prefix = \"clinicalpredict_\"\n",
    "    prepare_prediction_data(data_patient.drop('diagnosis', axis=1),\n",
    "                                nm_processing_dir_temp, \n",
    "                                drop_nans=True, \n",
    "                                batch_effects=['sex', 'site'], \n",
    "                                prefix=prefix)\n",
    "\n",
    "    testrespfile_path = os.path.join(nm_processing_dir_temp, prefix + 'y_test.pkl')\n",
    "    testcovfile_path = os.path.join(nm_processing_dir_temp, prefix + 'x_test.pkl')\n",
    "    tsbefile = os.path.join(nm_processing_dir_temp, prefix + 'b_test.pkl')\n",
    "\n",
    "    execute_nm(processing_dir_temp, python_path,\n",
    "            'NM', testcovfile_path, testrespfile_path, batch_size, memory, duration, alg='hbr', \n",
    "            log_path=nm_log_path, binary=True, tsbefile=tsbefile, func=\"predict\", \n",
    "            model_type=hbr_configs[method]['model_type'], likelihood=hbr_configs[method]['likelihood'],  \n",
    "            linear_sigma=hbr_configs[method]['linear_sigma'], random_slope_mu=hbr_configs[method]['random_slope_mu'],\n",
    "            linear_epsilon=hbr_configs[method]['linear_epsilon'], linear_delta=hbr_configs[method]['linear_delta'], \n",
    "            savemodel='True', inscaler=inscaler, outscaler=outscaler, outputsuffix=\"clinicalpredict\", inputsuffix=outputsuffix,\n",
    "            interactive='auto', cluster_spec=cluster_spec, nuts_sampler=\"nutpie\", n_cores_per_batch=\"2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABNORMALITY PROBABILITY INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=merged_data.columns[3:])\n",
    "df_auc = pd.DataFrame(columns=merged_data.columns[3:])\n",
    "\n",
    "\n",
    "for i in range(len(random_seeds)):\n",
    "\n",
    "    nm_processing_dir_temp = nm_processing_dir.replace(\"Run_0\", f\"Run_{i}\")\n",
    "    processing_dir_temp = processing_dir.replace(\"Run_0\", f\"Run_{i}\")\n",
    "\n",
    "    with open(os.path.join(processing_dir_temp, \"Z_clinicalpredict.pkl\"), \"rb\") as file:\n",
    "        z_patient = pickle.load(file)\n",
    "\n",
    "    with open(os.path.join(processing_dir_temp,\"Z_estimate.pkl\"), \"rb\") as file:\n",
    "        z_healthy = pickle.load(file)\n",
    "\n",
    "    with open(os.path.join(nm_processing_dir_temp, \"b_test.pkl\"), \"rb\") as file:\n",
    "        b_healthy = pickle.load(file)\n",
    "\n",
    "\n",
    "    z_healthy = z_healthy.iloc[np.where(b_healthy[\"site\"]==3)[0], :]\n",
    "\n",
    "    data_patient = data_patient.dropna(axis=0)\n",
    "    z_patient = z_patient.iloc[np.where(data_patient[\"diagnosis\"].isin([\"adhd combined type\", \"adhd inattentive type\",\"adhd hyperactive impulsive type\" ]))[0], :]\n",
    "\n",
    "\n",
    "    p_patient = z_to_abnormal_p(z_patient)\n",
    "    p_healthy = z_to_abnormal_p(z_healthy)\n",
    "\n",
    "    p = np.concatenate([p_patient, p_healthy])\n",
    "    print(p.shape)\n",
    "\n",
    "    labels = np.concatenate([np.ones(p_patient.shape[0]), np.zeros(p_healthy.shape[0])])\n",
    "    print(labels.shape)\n",
    "\n",
    "    auc, p_val = anomaly_detection_auc(p, labels, n_permutation=1000)\n",
    "    \n",
    "    p_val = false_discovery_control(p_val)\n",
    "\n",
    "    df.loc[i] = p_val\n",
    "    df_auc.loc[i] = auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC BOXPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc_plot = df_auc[[\"Adjusted_Canonical_Relative_PowerTheta_all\", \n",
    "                      \"Adjusted_Canonical_Relative_PowerAlpha_all\",\n",
    "                      \"Adjusted_Canonical_Relative_PowerBeta_all\",\n",
    "                      \"Adjusted_Canonical_Relative_PowerGamma_all\"]]\n",
    "df_auc_plot.columns = [\"Theta\", \"Alpha\", \"Beta\", \"Gamma\"]\n",
    "\n",
    "box_plot_auc(df_auc_plot, save_path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_patient = data_patient.iloc[np.where(data_patient[\"diagnosis\"].isin([\"adhd combined type\", \"adhd inattentive type\",\"adhd hyperactive impulsive type\" ]))[0], :]\n",
    "\n",
    "print(data_patient.shape)\n",
    "\n",
    "z_patient.index = data_patient.index\n",
    "adhd_patient_feat = data_patient.iloc[:,4:]\n",
    "print(adhd_patient_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "a = list(z_patient.iloc[:, np.where(adhd_patient_feat.columns==\"Adjusted_Canonical_Relative_PowerTheta_all\")[0][0]])\n",
    "b = list(z_patient.iloc[:, np.where(adhd_patient_feat.columns==\"Adjusted_Canonical_Relative_PowerBeta_all\")[0][0]])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.ylim((-4, 4))\n",
    "plt.xlim((-4, 4))\n",
    "\n",
    "# Define the fixed order of labels and corresponding colors\n",
    "order = [\n",
    "    ('High beta - Low theta', 'red'),\n",
    "    ('High theta - Low beta', 'purple'),\n",
    "    ('High beta - Normal theta', 'blue'),\n",
    "    ('Normal theta - Low beta', 'orange'),\n",
    "    ('Normal beta - High theta', 'green'),\n",
    "    ('Normal beta - Low theta', 'teal'),\n",
    "    ('Low beta - Low theta', 'pink'),\n",
    "    ('High beta - High theta', 'mediumvioletred'),\n",
    "    ('Normal range', 'black')\n",
    "]\n",
    "\n",
    "# Initialize lists for colors and labels\n",
    "colors = []\n",
    "labels = []\n",
    "\n",
    "# Assign colors and labels based on conditions\n",
    "for theta, beta in zip(a, b):\n",
    "    if beta > 0.68 and theta < -0.68:\n",
    "        colors.append('red')\n",
    "        labels.append('High beta - Low theta')\n",
    "    elif theta > 0.68 and beta < -0.68:\n",
    "        colors.append('purple')\n",
    "        labels.append('High theta - Low beta')\n",
    "    elif beta > 0.68 and -0.68 < theta < 0.68:\n",
    "        colors.append(\"blue\")\n",
    "        labels.append('High beta - Normal theta')\n",
    "    elif -.68 < theta < 0.68 and beta < -0.68:\n",
    "        colors.append(\"orange\")\n",
    "        labels.append('Normal theta - Low beta')\n",
    "    elif -0.68 < beta < 0.68 and theta > 0.68:\n",
    "        colors.append(\"olive\")\n",
    "        labels.append('Normal beta - High theta')\n",
    "    elif -0.68 < beta < 0.68 and theta < -0.68:\n",
    "        colors.append(\"teal\")\n",
    "        labels.append('Normal beta - Low theta')\n",
    "\n",
    "    elif  beta < -0.68 and theta < -0.68:\n",
    "        colors.append(\"pink\")\n",
    "        labels.append('Low beta - Low theta')\n",
    "    elif  beta > 0.68 and theta > 0.68:\n",
    "        colors.append(\"mediumvioletred\")\n",
    "        labels.append('High beta - High theta')\n",
    "    else:\n",
    "        colors.append('black')\n",
    "        labels.append('Normal range')\n",
    "\n",
    "# Create the legend handles in the correct order\n",
    "handles = []\n",
    "for label, color in order:\n",
    "    handles.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10, label=label))\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.scatter(a, b, color=colors)\n",
    "\n",
    "# Add the gray region and lines\n",
    "plt.fill_betweenx(y=[-0.68, 0.68], x1=-0.68, x2=0.68, color='gray', alpha=0.5, label=\"|z| < 0.68\")\n",
    "plt.hlines(y=[-0.68, 0.68], xmin=-0.68, xmax=0.68, colors='black', linestyles='--', linewidth=1.5)\n",
    "plt.vlines(x=[-0.68, 0.68], ymin=-0.68, ymax=0.68, colors='black', linestyles='--', linewidth=1.5)\n",
    "\n",
    "# Set axis ticks\n",
    "ticks = [-3, -0.68, 0, 0.68, 3]\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks)\n",
    "\n",
    "# Labeling\n",
    "plt.xlabel('Theta z-scores', fontsize=16)\n",
    "plt.ylabel('Beta z-scores', fontsize=16)\n",
    "\n",
    "# Style the plot\n",
    "plt.grid(alpha=0.5)\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"left\"].set_visible(False)\n",
    "plt.gca().spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "# Add the legend with the correct order\n",
    "plt.legend(handles=handles, fontsize=13)\n",
    "\n",
    "# Finalize and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"normal_var.png\", dpi=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote Cluster Kernel",
   "language": "python",
   "name": "cluster_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
