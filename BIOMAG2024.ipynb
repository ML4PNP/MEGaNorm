{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'meganorm-smkia'\n",
    "datasets = {'BTNRH': '/project/meganorm/Data/BTNRH/BTNRH/BIDS_data/',\n",
    "            'CAMCAN': '/project/meganorm/Data/BTNRH/CAMCAN/BIDS_data/'}\n",
    "package_path = f'/home/{username}/Code/MEGaNorm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(package_path)\n",
    "from utils.parallel import submit_jobs, check_jobs_status, collect_results\n",
    "from datasets.camcan import load_camcan_data\n",
    "from datasets.btnrh import load_BTNRH_data\n",
    "from utils.nm import hbr_data_split, estimate_centiles\n",
    "from plots.plots import plot_nm_range_site, plot_comparison, plot_neurooscillochart, plot_age_dist2\n",
    "from utils.nm import model_quantile_evaluation, calculate_oscilochart\n",
    "from utils.IO import make_config, merge_datasets\n",
    "import pandas as pd\n",
    "from pcntoolkit.normative_parallel import execute_nm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"BIOMAG2024\"\n",
    "project_dir = f'/home/{username}/Results/{project}/'\n",
    "\n",
    "mainParallel_path = os.path.join(package_path, 'src', 'mainParallel.py')\n",
    "\n",
    "features_dir = os.path.join(project_dir, 'Features')\n",
    "features_log_path = os.path.join(features_dir, 'log')\n",
    "features_temp_path = os.path.join(features_dir,'temp')\n",
    "\n",
    "nm_processing_dir = os.path.join(project_dir, 'NM')\n",
    "\n",
    "job_configs = {'log_path':features_log_path, 'module':'mne', 'time':'1:00:00', 'memory':'20GB', \n",
    "                'partition':'normal', 'core':1, 'node':1, 'batch_file_name':'batch_job'}\n",
    "\n",
    "if not os.path.isdir(features_log_path):\n",
    "    os.makedirs(features_log_path)\n",
    "\n",
    "if not os.path.isdir(features_temp_path):\n",
    "    os.makedirs(features_temp_path)\n",
    "    \n",
    "if not os.path.isdir(nm_processing_dir):\n",
    "    os.makedirs(nm_processing_dir)\n",
    "    \n",
    "configs = make_config(project, project_dir)\n",
    "\n",
    "subjects = merge_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parallel feature extraction  \n",
    "\n",
    "# Running Jobs\n",
    "start_time = submit_jobs(mainParallel_path, features_dir, subjects, \n",
    "                features_temp_path, job_configs=job_configs)\n",
    "# Checking jobs\n",
    "failed_jobs = check_jobs_status(username, start_time)\n",
    "\n",
    "falied_subjects = {failed_job:subjects[failed_job] for failed_job in failed_jobs}\n",
    "\n",
    "while len(failed_jobs)>0:\n",
    "    # Re-running Jobs\n",
    "    start_time = submit_jobs(mainParallel_path, features_dir, falied_subjects, \n",
    "                features_temp_path, job_configs=job_configs, config_file=os.path.join(project_dir, project+'.json'))\n",
    "    # Checking jobs\n",
    "    failed_jobs = check_jobs_status(username, start_time)\n",
    "\n",
    "collect_results(features_dir, subjects, features_temp_path, file_name='all_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preparation for Normative Modeling\n",
    "\n",
    "feature_path = os.path.join(features_dir, \"all_features.csv\")\n",
    "BTNRH_cov_path = \"/project/meganorm/Data/BTNRH/BTNRH/BIDS_data/participants.tsv\"\n",
    "camcan_cov_path = '/project/meganorm/Data/camcan/CamCAN/cc700/participants.tsv'\n",
    "\n",
    "camcan_data = load_camcan_data(feature_path, camcan_cov_path)\n",
    "BTNRH_data = load_BTNRH_data(feature_path, BTNRH_cov_path)\n",
    "\n",
    "merged_data = pd.concat([BTNRH_data, camcan_data], axis=0)\n",
    "\n",
    "merged_data['age'] = merged_data['age']/100\n",
    "\n",
    "biomarker_num = hbr_data_split(merged_data, nm_processing_dir, drop_nans=True, batch_effects=['gender', 'site'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting up NM configs\n",
    "\n",
    "python_path = '/project/meganorm/Software/Miniconda3/envs/mne/bin/python' \n",
    "\n",
    "hbr_configs = {\n",
    "                'homo_Gaussian_linear':{'model_type':'linear', 'likelihood':'Normal', 'linear_sigma':'False',\n",
    "                                   'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                'homo_Gaussian_bspline':{'model_type':'bspline', 'likelihood':'Normal', 'linear_sigma':'False',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                'homo_SHASH_linear':{'model_type':'linear', 'likelihood':'SHASHb', 'linear_sigma':'False',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                'homo_SHASH_bspline':{'model_type':'bspline', 'likelihood':'SHASHb', 'linear_sigma':'False',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                'hetero_Gaussian_linear':{'model_type':'linear', 'likelihood':'Normal', 'linear_sigma':'True',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'},\n",
    "                'hetero_Gaussian_bspline':{'model_type':'bspline', 'likelihood':'Normal', 'linear_sigma':'True',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'},\n",
    "                'hetero_SHASH_linear':{'model_type':'linear', 'likelihood':'SHASHb', 'linear_sigma':'True',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'True', 'linear_delta':'True'},\n",
    "                'hetero_SHASH_bspline':{'model_type':'bspline', 'likelihood':'SHASHb', 'linear_sigma':'True',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'True', 'linear_delta':'True'},\n",
    "            }\n",
    "\n",
    "inscaler='None' \n",
    "outscaler='minmax' \n",
    "batch_size = 1\n",
    "outputsuffix = '_estimate'\n",
    "\n",
    "respfile = os.path.join(nm_processing_dir, 'y_train.pkl')\n",
    "covfile = os.path.join(nm_processing_dir, 'x_train.pkl')\n",
    "\n",
    "testrespfile_path = os.path.join(nm_processing_dir, 'y_test.pkl')\n",
    "testcovfile_path = os.path.join(nm_processing_dir, 'x_test.pkl')\n",
    "\n",
    "trbefile = os.path.join(nm_processing_dir, 'b_train.pkl')\n",
    "tsbefile = os.path.join(nm_processing_dir, 'b_test.pkl')\n",
    "\n",
    "memory = '2gb'\n",
    "duration = '5:00:00'\n",
    "cluster_spec = 'slurm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Running NM\n",
    "\n",
    "#for method in hbr_configs.keys():\n",
    "method = 'hetero_SHASH_bspline'\n",
    "processing_dir = os.path.join(nm_processing_dir, method) + '/'\n",
    "nm_log_path = os.path.join(processing_dir, 'log') + '/'\n",
    "\n",
    "if not os.path.isdir(processing_dir):\n",
    "    os.makedirs(processing_dir)\n",
    "if not os.path.isdir(nm_log_path):\n",
    "    os.makedirs(nm_log_path)\n",
    "\n",
    "execute_nm(processing_dir, python_path,\n",
    "            'NM', covfile, respfile, batch_size, memory, duration, alg='hbr', \n",
    "            log_path=nm_log_path, binary=True, testcovfile_path=testcovfile_path, \n",
    "            testrespfile_path=testrespfile_path,trbefile=trbefile, tsbefile=tsbefile, \n",
    "            model_type=hbr_configs[method]['model_type'], likelihood=hbr_configs[method]['likelihood'],  \n",
    "            linear_sigma=hbr_configs[method]['linear_sigma'], random_slope_mu=hbr_configs[method]['random_slope_mu'],\n",
    "            linear_epsilon=hbr_configs[method]['linear_epsilon'], linear_delta=hbr_configs[method]['linear_delta'], \n",
    "            savemodel='True', inscaler=inscaler, outscaler=outscaler, outputsuffix=outputsuffix, \n",
    "            interactive='auto', cluster_spec=cluster_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluating quantiles using MACE\n",
    "\n",
    "hbr_configs = {\n",
    "                'hetero_SHASH_bspline':{'model_type':'bspline', 'likelihood':'SHASHb', 'linear_sigma':'True',\n",
    "                                    'random_slope_mu':'True', 'linear_epsilon':'True', 'linear_delta':'True'},\n",
    "                'hetero_SHASH_bspline2':{'model_type':'bspline', 'likelihood':'SHASHb', 'linear_sigma':'True',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'True', 'linear_delta':'True'},\n",
    "            }\n",
    "mace, best_models, bio_ids = model_quantile_evaluation(hbr_configs, nm_processing_dir, testcovfile_path, \n",
    "                              testrespfile_path, tsbefile, biomarker_num, plot=False, outputsuffix='estimate')\n",
    "\n",
    "\n",
    "plot_comparison(nm_processing_dir, hbr_configs, biomarker_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbr_configs = {\n",
    "                'hetero_SHASH_bspline2':{'model_type':'bspline', 'likelihood':'SHASHb', 'linear_sigma':'True',\n",
    "                                    'random_slope_mu':'False', 'linear_epsilon':'True', 'linear_delta':'True'},\n",
    "            }\n",
    "\n",
    "## Plotting ranges\n",
    "for config in hbr_configs.keys():\n",
    "    processing_path = os.path.join(nm_processing_dir, config)\n",
    "    \n",
    "    q = estimate_centiles(processing_path, biomarker_num, quantiles=[0.05, 0.25, 0.5, 0.75, 0.95],\n",
    "                          batch_map={0:{'Male':0, 'Female':1}, 1:{'CAMCAN':0,'BTNRH':1}}, \n",
    "                          age_range=[6, 85])\n",
    "    plot_nm_range_site(processing_path, nm_processing_dir, experiment_id=2)\n",
    "\n",
    "# exp 0: ap - periodic > 0 => 0 and hetero_SHASH_bspline\n",
    "# exp 1: hetero_SHASH_bspline\n",
    "# exp 2:  ap - periodic > 0 => 0 and hetero_SHASH_bspline and -inf are removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculateing Oscilograms\n",
    "\n",
    "model_path = f'/home/{username}/Results/BIOMAG2024/NM/hetero_SHASH_bspline/Models'\n",
    "\n",
    "gender_ids = {'Male':0, 'Female':1}\n",
    "frequency_band_model_ids = {'Theta':6, 'Alpha':3, 'Beta':4, 'Gamma':5}\n",
    "\n",
    "oscilograms = calculate_oscilochart(model_path, gender_ids, frequency_band_model_ids)\n",
    "\n",
    "plot_neurooscillochart(oscilograms, nm_processing_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Running Freesurfer on T1 Anatomical data for source reconstruction\n",
    "\n",
    "from utils.freesurfer import run_parallel_reconall\n",
    "\n",
    "mri_directory = '/project/meganorm/Data/camcan/CamCAN/cc700/mri/pipeline/release004/BIDS_20190411/anat'\n",
    "processing_dir = '/home/meganorm-smkia/temp'\n",
    "freesurfer_path = '/project/meganorm/Software/freesurfer'\n",
    "results_directory = '/project/meganorm/Data/camcan/CamCAN/cc700/mri/pipeline/release004/BIDS_20190411/derivatives'\n",
    "\n",
    "subject_ids = run_parallel_reconall(mri_directory, results_directory, processing_dir, freesurfer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re-running the failed recon-all jobs, Run this cell when all the jobs above are finished.\n",
    "from utils.freesurfer import check_log_for_success, rerun_failed_subs\n",
    "\n",
    "failed_jobs = check_log_for_success(results_directory, subject_ids)\n",
    "rerun_failed_subs(failed_jobs, mri_directory, results_directory, \n",
    "                          processing_dir, freesurfer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC on freesurfer results\n",
    "\n",
    "from utils.freesurfer import freesurfer_QC\n",
    "qc_passed_samples, qc_failed_samples, missing_samples = freesurfer_QC(results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot age distribution for different sites and train/test/validation partitions\n",
    "base_dir = \"/home/meganorm-mznasrabadi/Results/BIOMAG2024/NM\"\n",
    "plot_age_dist2(base_dir, val=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcntoolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
