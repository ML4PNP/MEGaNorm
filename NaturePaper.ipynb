{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seeds = [42, 100, 0, 10, 13, 20, 3, 18, 23, 105]\n",
    "run = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'meganorm-mznasrabadi'\n",
    "datasets = {\n",
    "    'BTNRH': {\n",
    "        'base_dir': '/project/meganorm/Data/BTNRH/BIDS',\n",
    "        'task': \"task-rest\",\n",
    "        \"ending\" : \"meg.fif\"\n",
    "    },\n",
    "    'CAMCAN': {\n",
    "        'base_dir': '/project/meganorm/Data/camcan/BIDS',\n",
    "        'task': \"task-rest\",\n",
    "        \"ending\" : \"meg.fif\"\n",
    "    },\n",
    "    'NIMH': {\n",
    "        'base_dir': '/project/meganorm/Data/NIMH',\n",
    "        'task': \"task-rest\",\n",
    "        \"ending\" : \"meg.ds\"\n",
    "    },\n",
    "    'OMEGA': {\n",
    "        'base_dir': '/project/meganorm/Data/Omega',\n",
    "        'task': \"task-rest\",\n",
    "        \"ending\" : \"meg.ds\"\n",
    "    },\n",
    "    'HCP': {\n",
    "        'base_dir': '/project/meganorm/Data/HCP',\n",
    "        'task': \"\",\n",
    "        \"ending\" : \"4-Restin/4D\"\n",
    "    }\n",
    "    }\n",
    "\n",
    "package_path = f'/home/{username}/MEGaNorm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(package_path)\n",
    "from utils.parallel import submit_jobs, check_jobs_status, collect_results\n",
    "from utils.nm import hbr_data_split, estimate_centiles, evaluate_mace, shapiro_stat, abnormal_probability\n",
    "from plots.plots import plot_nm_range_site2, plot_comparison, plot_neurooscillochart, plot_age_dist2, plot_growthcharts, plot_quantile_gauge, box_plot_auc\n",
    "from utils.nm import model_quantile_evaluation, calculate_oscilochart, prepare_prediction_data, cal_stats_for_gauge\n",
    "from utils.IO import merge_datasets_with_regex, merge_fidp_demo, merge_datasets_with_glob\n",
    "import pandas as pd\n",
    "import json\n",
    "from pcntoolkit.normative_parallel import execute_nm, rerun_nm, collect_nm\n",
    "import warnings\n",
    "import pickle  \n",
    "import numpy as np\n",
    "from pcntoolkit.util.utils import z_to_abnormal_p, anomaly_detection_auc\n",
    "from scipy.stats import false_discovery_control\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_config(project, path=None):\n",
    "\n",
    "    # preprocess configurations =================================================\n",
    "    # downsample data\n",
    "    config = dict()\n",
    "\n",
    "    # You could also set layout to None to have high \n",
    "    # choices: all, lobe, None\n",
    "    config[\"which_layout\"] = \"all\"\n",
    "\n",
    "    # which sensor type should be used\n",
    "    # choices: meg, mag, grad, eeg, opm\n",
    "    config[\"which_sensor\"] = \"meg\"\n",
    "    # config['fs'] = 1000\n",
    "\n",
    "    # ICA configuration\n",
    "    config['ica_n_component'] = 30\n",
    "    config['ica_max_iter'] = 800\n",
    "    config['ica_method'] = \"fastica\"\n",
    "\n",
    "    # lower and upper cutoff frequencies in a bandpass filter\n",
    "    config['cutoffFreqLow'] = 1\n",
    "    config['cutoffFreqHigh'] = 45\n",
    "\n",
    "    config[\"resampling_rate\"] = 1000\n",
    "    config[\"digital_filter\"] = True\n",
    "    config[\"notch_filter\"] = False\n",
    "\n",
    "    config[\"apply_ica\"] = True\n",
    "\n",
    "    config[\"auto_ica_corr_thr\"] = 0.9\n",
    "\n",
    "    # options are \"average\", \"REST\", and None \n",
    "    config[\"rereference_method\"]= \"average\"\n",
    "\n",
    "    # variance threshold across time\n",
    "    config[\"mag_var_threshold\"] = 4e-12\n",
    "    config[\"grad_var_threshold\"] = 4000e-13\n",
    "    config[\"eeg_var_threshold\"] = 40e-6\n",
    "    # flatness threshold across time\n",
    "    config[\"mag_flat_threshold\"] = 10e-15\n",
    "    config[\"grad_flat_threshold\"] = 10e-15\n",
    "    config[\"eeg_flat_threshold\"] = 40e-6\n",
    "    # variance thershold across channels\n",
    "    config[\"zscore_std_thresh\"] = 15 # change this\n",
    "\n",
    "    # segmentation ==============================================\n",
    "    #start time of the raw data to use in seconds, this is to avoid possible eye blinks in close-eyed resting state. \n",
    "    config['segments_tmin'] = 20\n",
    "    # end time of the raw data to use in seconds, this is to avoid possible eye blinks in close-eyed resting state.\n",
    "    config['segments_tmax'] = -20\n",
    "    # length of MEG segments in seconds\n",
    "    config['segments_length'] = 10\n",
    "    # amount of overlap between MEG sigals in seconds\n",
    "    config['segments_overlap'] = 2\n",
    "\n",
    "    # PSD ==============================================\n",
    "    # Spectral estimation method\n",
    "    config['psd_method'] = \"welch\"\n",
    "    # amount of overlap between windows in Welch's method\n",
    "    config['psd_n_overlap'] = 1\n",
    "    config['psd_n_fft'] = 2\n",
    "    # number of samples in psd\n",
    "    config[\"psd_n_per_seg\"] = 2\n",
    "\n",
    "    # fooof analysis configurations ==============================================\n",
    "    # Desired frequency range to run FOOOF\n",
    "    config['fooof_freqRangeLow'] = 3\n",
    "    config['fooof_freqRangeHigh'] = 40\n",
    "    # which mode should be used for fitting; choices (knee, fixed)\n",
    "    config[\"aperiodic_mode\"] = \"knee\"\n",
    "    # minimum acceptable peak width in fooof analysis\n",
    "    config[\"fooof_peak_width_limits\"] = [1.0, 12.0]\n",
    "    #Absolute threshold for detecting peaks\n",
    "    config['fooof_min_peak_height'] = 0\n",
    "    #Relative threshold for detecting peaks\n",
    "    config['fooof_peak_threshold'] = 2\n",
    "\n",
    "    # feature extraction ==========================================================\n",
    "    # Define frequency bands\n",
    "    config['freq_bands'] = {\n",
    "                            'Theta': (3, 8),\n",
    "                            'Alpha': (8, 13),\n",
    "                            'Beta': (13, 30),\n",
    "                            'Gamma': (30, 40),\n",
    "                            # 'Broadband': (3, 40)\n",
    "                            }\n",
    "\n",
    "    # Define individualized frequency range over main peaks in each freq band\n",
    "    config['individualized_band_ranges'] = { \n",
    "                                            'Theta': (-2, 3),\n",
    "                                            'Alpha': (-2, 3), # change to (-4,2)\n",
    "                                            'Beta': (-8, 9),\n",
    "                                            'Gamma': (-5, 5)\n",
    "                                            }\n",
    "\n",
    "    # least acceptable R squred of fitted models\n",
    "    config['min_r_squared'] = 0.9 \n",
    " \n",
    "    config['feature_categories'] = {\n",
    "                                    \"Offset\":False,\n",
    "                                    \"Exponent\":False,\n",
    "                                    \"Peak_Center\":False,\n",
    "                                    \"Peak_Power\":False,\n",
    "                                    \"Peak_Width\":False,\n",
    "                                    \"Adjusted_Canonical_Relative_Power\":True, \n",
    "                                    \"Adjusted_Canonical_Absolute_Power\":False,\n",
    "                                    \"Adjusted_Individualized_Relative_Power\":False,\n",
    "                                    \"Adjusted_Individualized_Absolute_Power\":False,\n",
    "                                    \"OriginalPSD_Canonical_Relative_Power\":False, \n",
    "                                    \"OriginalPSD_Canonical_Absolute_Power\":False,\n",
    "                                    \"OriginalPSD_Individualized_Relative_Power\":False,\n",
    "                                    \"OriginalPSD_Individualized_Absolute_Power\":False,\n",
    "                                    }\n",
    "    \n",
    "    config[\"fooof_res_save_path\"] = None\n",
    "\n",
    "    config[\"random_state\"] = 42\n",
    "\n",
    "    if path is not None:\n",
    "        out_file = open(os.path.join(path, project + \".json\"), \"w\") \n",
    "        json.dump(config, out_file, indent = 6) \n",
    "        out_file.close()\n",
    "\n",
    "    return config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"_natureCommunicationPaper\"\n",
    "\n",
    "project_dir = f'/home/{username}/Results/{project}/'\n",
    "\n",
    "mainParallel_path = os.path.join(package_path, 'src', 'mainParallel.py')\n",
    "\n",
    "features_dir = os.path.join(project_dir, 'Features')\n",
    "features_log_path = os.path.join(features_dir, 'log')\n",
    "features_temp_path = os.path.join(features_dir,'temp')\n",
    "\n",
    "nm_processing_dir = os.path.join(project_dir, 'NM', 'Run_' + str(run))\n",
    "\n",
    "job_configs = {'log_path':features_log_path, 'module':'mne', 'time':'1:00:00', 'memory':'20GB', \n",
    "                'partition':'normal', 'core':1, 'node':1, 'batch_file_name':'batch_job'}\n",
    "\n",
    "if not os.path.isdir(features_log_path):\n",
    "    os.makedirs(features_log_path)\n",
    "\n",
    "if not os.path.isdir(features_temp_path):\n",
    "    os.makedirs(features_temp_path)\n",
    "    \n",
    "if not os.path.isdir(nm_processing_dir):\n",
    "    os.makedirs(nm_processing_dir)\n",
    "    \n",
    "configs = make_config(project, project_dir)\n",
    "\n",
    "subjects = merge_datasets_with_glob(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f-IDPs extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parallel feature extraction  \n",
    "\n",
    "# # Running Jobs\n",
    "# start_time = submit_jobs(mainParallel_path, features_dir, subjects, \n",
    "#                 features_temp_path, job_configs=job_configs, config_file=os.path.join(project_dir, project+'.json'))\n",
    "# # Checking jobs\n",
    "# failed_jobs = check_jobs_status(username, start_time)\n",
    "\n",
    "# falied_subjects = {failed_job:subjects[failed_job] for failed_job in failed_jobs}\n",
    "\n",
    "# while len(failed_jobs)>0:\n",
    "#     # Re-running Jobs\n",
    "#     start_time = submit_jobs(mainParallel_path, features_dir, falied_subjects, \n",
    "#                 features_temp_path, job_configs=job_configs, config_file=os.path.join(project_dir, project+'.json'))\n",
    "#     # Checking jobs\n",
    "#     failed_jobs = check_jobs_status(username, start_time)\n",
    "\n",
    "# collect_results(features_dir, subjects, features_temp_path, file_name='all_features', clean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preparation for Normative Modeling\n",
    "data_base_dirs = [values[\"base_dir\"] for values in datasets.values()]\n",
    "dataset_names = list(datasets.keys())\n",
    "merged_data, data_patient = merge_fidp_demo(data_base_dirs, features_dir, dataset_names, include_patients=False)\n",
    "\n",
    "biomarker_num = hbr_data_split(merged_data, nm_processing_dir, drop_nans=True, batch_effects=['sex', 'site'], random_seed=random_seeds[run], train_split=0.5)\n",
    "\n",
    "biomarker_names = list(merged_data.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 2\n",
    "print(\"Dataset name:\", list(datasets.keys())[site])\n",
    "print(\"size: \", merged_data[merged_data.site==site].shape[0], \"participants\")\n",
    "print(\"mean age: \", merged_data[merged_data.site==site][\"age\"].mean())\n",
    "print(\"std age: \", merged_data[merged_data.site==site][\"age\"].std())\n",
    "print(\"female num: \", merged_data[np.logical_and(merged_data.site==site, merged_data.sex==1)].shape[0], \"participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting up NM configs\n",
    "\n",
    "python_path = '/project/meganorm/Software/Miniconda3/envs/mne/bin/python' \n",
    "\n",
    "hbr_configs = {\n",
    "                # 'homo_Gaussian_linear':{'model_type':'linear', 'likelihood':'Normal', 'linear_sigma':'False',\n",
    "                #                         'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                # 'homo_Gaussian_bspline':{'model_type':'bspline', 'likelihood':'Normal', 'linear_sigma':'False',\n",
    "                #                         'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                # 'homo_SHASH_linear':{'model_type':'linear', 'likelihood':'SHASHb', 'linear_sigma':'False',\n",
    "                #                     'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                # 'homo_SHASH_bspline':{'model_type':'bspline', 'likelihood':'SHASHb', 'linear_sigma':'False',\n",
    "                #                     'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'}, \n",
    "                # 'hetero_Gaussian_linear':{'model_type':'linear', 'likelihood':'Normal', 'linear_sigma':'True',\n",
    "                #                         'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'},\n",
    "                # 'hetero_Gaussian_bspline':{'model_type':'bspline', 'likelihood':'Normal', 'linear_sigma':'True',\n",
    "                #                         'random_slope_mu':'False', 'linear_epsilon':'False', 'linear_delta':'False'},\n",
    "                # 'hetero_SHASH_linear':{'model_type':'linear', 'likelihood':'SHASHb', 'linear_sigma':'True',\n",
    "                #                     'random_slope_mu':'False', 'linear_epsilon':'True', 'linear_delta':'True'},\n",
    "                'hetero_SHASH_bspline':{'model_type':'bspline', 'likelihood':'SHASHb', 'linear_sigma':'True',\n",
    "                                        'random_slope_mu':'False', 'linear_epsilon':'True', 'linear_delta':'True'},\n",
    "            }\n",
    "\n",
    "inscaler='None' \n",
    "outscaler='None' \n",
    "batch_size = 1\n",
    "outputsuffix = '_estimate'\n",
    "\n",
    "respfile = os.path.join(nm_processing_dir, 'y_train.pkl')\n",
    "covfile = os.path.join(nm_processing_dir, 'x_train.pkl')\n",
    "\n",
    "testrespfile_path = os.path.join(nm_processing_dir, 'y_test.pkl')\n",
    "testcovfile_path = os.path.join(nm_processing_dir, 'x_test.pkl')\n",
    "\n",
    "trbefile = os.path.join(nm_processing_dir, 'b_train.pkl')\n",
    "tsbefile = os.path.join(nm_processing_dir, 'b_test.pkl')\n",
    "\n",
    "memory = '2gb'\n",
    "duration = '5:00:00'\n",
    "cluster_spec = 'slurm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running NM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for method in hbr_configs.keys():\n",
    "method = 'hetero_SHASH_bspline'\n",
    "processing_dir = os.path.join(nm_processing_dir, method) + '/'\n",
    "nm_log_path = os.path.join(processing_dir, 'log') + '/'\n",
    "\n",
    "if not os.path.isdir(processing_dir):\n",
    "    os.makedirs(processing_dir)\n",
    "if not os.path.isdir(nm_log_path):\n",
    "    os.makedirs(nm_log_path)\n",
    "\n",
    "# execute_nm(processing_dir, python_path,\n",
    "#             'NM', covfile, respfile, batch_size, memory, duration, alg='hbr', \n",
    "#             log_path=nm_log_path, binary=True, testcovfile_path=testcovfile_path, \n",
    "#             testrespfile_path=testrespfile_path,trbefile=trbefile, tsbefile=tsbefile, \n",
    "#             model_type=hbr_configs[method]['model_type'], likelihood=hbr_configs[method]['likelihood'],  \n",
    "#             linear_sigma=hbr_configs[method]['linear_sigma'], random_slope_mu=hbr_configs[method]['random_slope_mu'],\n",
    "#             linear_epsilon=hbr_configs[method]['linear_epsilon'], linear_delta=hbr_configs[method]['linear_delta'], \n",
    "#             savemodel='True', inscaler=inscaler, outscaler=outscaler, outputsuffix=outputsuffix, \n",
    "#             interactive='auto', cluster_spec=cluster_spec, nuts_sampler=\"nutpie\", n_cores_per_batch=\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_nm(processing_dir, \"NM\", collect=True, binary=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def aggregate_metrics_across_runs(path, method_name, biomarker_names, valcovfile_path,\n",
    "                                valrespfile_path, valbefile,  metrics = [\"skewness\", \"kurtosis\", \"W\"], \n",
    "                                num_runs=10, quantiles=[0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99],\n",
    "                                outputsuffix='estimate'):\n",
    "    \n",
    "    # index_labels = [metric + \"_\" + biomarker_name for metric in metrics for biomarker_name in biomarker_names]\n",
    "    # df = pd.DataFrame(index=index_labels, columns=list(range(10)))\n",
    "    data = {metric: {biomarker_name: [] for biomarker_name in biomarker_names} \n",
    "                                for metric in metrics}\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        run_path = path.replace(\"Run_0\", f\"Run_{run}\")\n",
    "        with open(os.path.join(run_path, method_name, 'Z_estimate.pkl'), 'rb') as file:\n",
    "            z_scores = pickle.load(file)\n",
    "            \n",
    "            for metric in metrics:\n",
    "                values = []\n",
    "\n",
    "                if metric == \"MACE\":\n",
    "                    for ind in range(len(biomarker_names)):\n",
    "                        values.append(evaluate_mace(os.path.join(run_path, method, 'Models'), valcovfile_path, \n",
    "                                                    valrespfile_path, valbefile, model_id=ind,\n",
    "                                                    quantiles=quantiles,\n",
    "                                                    outputsuffix=outputsuffix))\n",
    "                        \n",
    "                if metric == \"W\":\n",
    "                    with open(os.path.join(run_path, 'x_test.pkl'), 'rb') as file:\n",
    "                        cov = pickle.load(file)\n",
    "                    values.extend(shapiro_stat(z_scores, cov))\n",
    "\n",
    "                if metric == \"skewness\":\n",
    "                    values.extend(skew(z_scores))\n",
    "                \n",
    "                if metric == \"kurtosis\":\n",
    "                    values.extend(kurtosis(z_scores))\n",
    "\n",
    "                for counter, name in enumerate(biomarker_names):\n",
    "                    data[metric][name].append(values[counter])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_values = aggregate_metrics_across_runs(nm_processing_dir, method, biomarker_names, testcovfile_path, \n",
    "                              testrespfile_path, tsbefile,\n",
    "                               )\n",
    "metrics_summary_path = \"/home/meganorm-mznasrabadi/Results/_natureCommunicationPaper/NM/Run_0/hetero_SHASH_bspline/metrics_summary.pkl\"\n",
    "with open(metrics_summary_path, \"wb\") as file:\n",
    "    pickle.dump(metrics_values, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def plot_metrics(metrics_path, biomarker_names, which_features,\n",
    "                  feature_new_name=[]):\n",
    "\n",
    "    # Use valid hexadecimal colors\n",
    "    colors = [\"#9E6240\", \"#819595\", \"#5F0F40\", \"#0F4C5C\"]\n",
    "    \n",
    "    with open(metrics_path, \"rb\") as file:\n",
    "        metrics_dic = pickle.load(file)\n",
    "    \n",
    "    for metric in metrics_dic.keys():\n",
    "        df_temp = pd.DataFrame(metrics_dic.get(metric)).loc[:, which_features]\n",
    "        df_temp.columns = feature_new_name\n",
    "        \n",
    "        # Reshape the data for boxplot\n",
    "        df_temp = df_temp.melt(var_name='Variable', value_name='Value')\n",
    "\n",
    "        sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "        \n",
    "        # Use palette instead of color\n",
    "        sns.boxplot(x='Variable', y='Value', data=df_temp, palette=colors)\n",
    "        sns.despine(offset=0, trim=True)\n",
    "        plt.xlabel(\"Frequency Bands\")\n",
    "        plt.ylabel(metric.title())\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "which_features = [\"Adjusted_Canonical_Relative_PowerTheta_all\", \"Adjusted_Canonical_Relative_PowerAlpha_all\", \n",
    "                  \"Adjusted_Canonical_Relative_PowerBeta_all\", \"Adjusted_Canonical_Relative_PowerGamma_all\"]\n",
    "plot_metrics(metrics_summary_path, biomarker_names, which_features, feature_new_name=[\"Theta\", \"Alpha\", \n",
    "                                                                                        \"Beta\", \"Gamma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_values[\"kurtosis\"][\"Adjusted_Canonical_Relative_PowerBeta_all\"]\n",
    "\n",
    "a = \"/home/meganorm-mznasrabadi/Results/_natureCommunicationPaper/NM/Run_9/hetero_SHASH_bspline/Z_estimate.pkl\"\n",
    "\n",
    "with open(a, 'rb') as file:\n",
    "    z_scores = pickle.load(file)\n",
    "\n",
    "sorted(z_scores.iloc[:,-2].tolist(), reverse=True)\n",
    "# np.where(np.array(metrics_values.iloc[:,2].tolist())==min(metrics_values.iloc[:,2].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluating quantiles using MACE\n",
    "\n",
    "mace, best_models, bio_ids = model_quantile_evaluation(hbr_configs, nm_processing_dir, testcovfile_path, \n",
    "                              testrespfile_path, tsbefile, biomarker_num, plot=False, outputsuffix='estimate')\n",
    "\n",
    "plot_comparison(nm_processing_dir, hbr_configs, biomarker_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NM range with markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ranges\n",
    "# # for config in hbr_configs.keys():\n",
    "processing_path = os.path.join(nm_processing_dir, method)\n",
    "\n",
    "q = estimate_centiles(processing_path, biomarker_num, quantiles=[0.05, 0.25, 0.5, 0.75, 0.95],\n",
    "                        batch_map={0:{'Male':0, 'Female':1}, 1:{'BTNRH':0, 'CAMCAN':1, \"NIMH\":2, \"OMEGA\":3, \"HCP\":4}}, \n",
    "                        age_range=[6, 80])\n",
    "plot_nm_range_site2(processing_path, nm_processing_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age distribution (plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_participants = pd.concat([merged_data, data_patient])\n",
    "\n",
    "plot_age_dist2(all_participants, site_names=list(datasets.keys()), save_path=\"/home/meganorm-mznasrabadi/MEGaNorm/pics/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_seeds = [0]\n",
    "for i in range(len(random_seeds)):\n",
    "\n",
    "    nm_processing_dir_temp = nm_processing_dir.replace(\"Run_0\", f\"Run_{i}\")\n",
    "    processing_dir_temp = processing_dir.replace(\"Run_0\", f\"Run_{i}\")\n",
    "\n",
    "    prefix = \"clinicalpredict_\"\n",
    "    prepare_prediction_data(data_patient.drop('diagnosis', axis=1),\n",
    "                                nm_processing_dir_temp, \n",
    "                                drop_nans=True, \n",
    "                                batch_effects=['sex', 'site'], \n",
    "                                prefix=prefix)\n",
    "\n",
    "    testrespfile_path = os.path.join(nm_processing_dir_temp, prefix + 'y_test.pkl')\n",
    "    testcovfile_path = os.path.join(nm_processing_dir_temp, prefix + 'x_test.pkl')\n",
    "    tsbefile = os.path.join(nm_processing_dir_temp, prefix + 'b_test.pkl')\n",
    "\n",
    "    execute_nm(processing_dir_temp, python_path,\n",
    "            'NM', testcovfile_path, testrespfile_path, batch_size, memory, duration, alg='hbr', \n",
    "            log_path=nm_log_path, binary=True, tsbefile=tsbefile, func=\"predict\", \n",
    "            model_type=hbr_configs[method]['model_type'], likelihood=hbr_configs[method]['likelihood'],  \n",
    "            linear_sigma=hbr_configs[method]['linear_sigma'], random_slope_mu=hbr_configs[method]['random_slope_mu'],\n",
    "            linear_epsilon=hbr_configs[method]['linear_epsilon'], linear_delta=hbr_configs[method]['linear_delta'], \n",
    "            savemodel='True', inscaler=inscaler, outscaler=outscaler, outputsuffix=\"clinicalpredict\", inputsuffix=outputsuffix,\n",
    "            interactive='auto', cluster_spec=cluster_spec, nuts_sampler=\"nutpie\", n_cores_per_batch=\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abnormal probability index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abnormal_probability(processing_dir, nm_processing_dir, site_id, n_permutation=1000):\n",
    "\n",
    "\n",
    "    with open(os.path.join(processing_dir, \"Z_clinicalpredict.pkl\"), \"rb\") as file:\n",
    "        z_patient = pickle.load(file)\n",
    "\n",
    "    with open(os.path.join(processing_dir,\"Z_estimate.pkl\"), \"rb\") as file:\n",
    "        z_healthy = pickle.load(file)\n",
    "\n",
    "    with open(os.path.join(nm_processing_dir, \"b_test.pkl\"), \"rb\") as file:\n",
    "        b_healthy = pickle.load(file)\n",
    "\n",
    "    z_healthy = z_healthy.iloc[np.where(b_healthy[\"site\"]==site_id)[0], :]\n",
    "\n",
    "    # z_patient = pd.concat([z_patient, np.sqrt((z_patient.iloc[:, [0, 1, 2, 3]]**2).mean(axis=1))], axis=1)\n",
    "    # z_healthy = pd.concat([z_healthy, np.sqrt((z_healthy.iloc[:, [0, 1, 2, 3]]**2).mean(axis=1))], axis=1)\n",
    "\n",
    "    p_patient = z_to_abnormal_p(z_patient)\n",
    "    p_healthy = z_to_abnormal_p(z_healthy)\n",
    "    \n",
    "    p_patient = np.hstack([p_patient, p_patient[:, [0, 2, 3]].mean(axis=1).reshape(-1, 1)])\n",
    "    p_healthy = np.hstack([p_healthy, p_healthy[:, [0, 2, 3]].mean(axis=1).reshape(-1, 1)])\n",
    "\n",
    "    p = np.concatenate([p_patient, p_healthy])\n",
    "    labels = np.concatenate([np.ones(p_patient.shape[0]), np.zeros(p_healthy.shape[0])])\n",
    "\n",
    "    auc, p_val = anomaly_detection_auc(p, labels, n_permutation=n_permutation)\n",
    "\n",
    "    p_val = false_discovery_control(p_val)\n",
    "\n",
    "    return p_val, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_id = 3\n",
    "p_vals, aucs = [], []\n",
    "\n",
    "for i in range(len(random_seeds)):\n",
    "\n",
    "    nm_processing_dir_temp = nm_processing_dir.replace(\"Run_0\", f\"Run_{i}\")\n",
    "    processing_dir_temp = processing_dir.replace(\"Run_0\", f\"Run_{i}\")\n",
    "\n",
    "    p_val, auc = abnormal_probability(processing_dir_temp,\n",
    "                                    nm_processing_dir_temp, \n",
    "                                    site_id,\n",
    "                                    n_permutation=1000)\n",
    "    \n",
    "    p_vals.append(p_val); aucs.append(auc)\n",
    "\n",
    "p_vals = pd.DataFrame(np.vstack(p_vals))\n",
    "aucs = pd.DataFrame(np.vstack(aucs))\n",
    "\n",
    "aucs.columns = [\"Theta\", \"Alpha\", \"Beta\", \"Gamma\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def box_plot_auc(df, save_path):\n",
    "\n",
    "    # Melt the DataFrame to long format for Seaborn\n",
    "    data_long = pd.melt(df)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    colors = ['#E6B213', 'sandybrown', '#E84653', 'lightseagreen']\n",
    "    sns.boxplot(x='variable', y='value', data=data_long, color=\"lightgray\")#, palette=colors)\n",
    "\n",
    "    sns.stripplot(x='variable', y='value', data=data_long, color='black', marker='o', size=6, alpha=0.7, jitter=True)\n",
    "\n",
    "    means = df.mean(axis=0)\n",
    "    for i, mean in enumerate(means):\n",
    "        plt.text(i, mean, '', color='black', ha='center', va='center', fontsize=2)\n",
    "\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    # plt.title('AUCs Across 10 Runs', fontsize=16)\n",
    "    plt.ylabel('AUC', fontsize=16)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.grid()\n",
    "\n",
    "\n",
    "    plt.gca().spines[\"right\"].set_visible(False)\n",
    "    plt.gca().spines[\"top\"].set_visible(False)\n",
    "    plt.gca().spines[\"left\"].set_visible(False)\n",
    "    plt.gca().spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Show the plot\n",
    "    plt.savefig(os.path.join(save_path, \"AUCs.svg\"), dpi=600, format=\"svg\")\n",
    "\n",
    "box_plot_auc(aucs, save_path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_patient = data_patient.iloc[np.where(data_patient[\"diagnosis\"] == \"parkinson\")[0], :]\n",
    "print(data_patient.shape)\n",
    "\n",
    "z_patient.index = data_patient.index\n",
    "parkinson_patient_feat = data_patient.iloc[:,4:]\n",
    "print(parkinson_patient_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "a = list(z_patient.iloc[:, np.where(parkinson_patient_feat.columns==\"Adjusted_Canonical_Relative_PowerTheta_all\")[0][0]])\n",
    "b = list(z_patient.iloc[:, np.where(parkinson_patient_feat.columns==\"Adjusted_Canonical_Relative_PowerBeta_all\")[0][0]])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.ylim((-4, 4))\n",
    "plt.xlim((-4, 4))\n",
    "\n",
    "# Define the fixed order of labels and corresponding colors\n",
    "order = [\n",
    "    ('High beta - Low theta', 'red'),\n",
    "    ('High theta - Low beta', 'purple'),\n",
    "    ('High beta - Normal theta', 'blue'),\n",
    "    ('Normal theta - Low beta', 'orange'),\n",
    "    ('Normal beta - High theta', 'green'),\n",
    "    ('Normal beta - Low theta', 'teal'),\n",
    "    ('Low beta - Low theta', 'pink'),\n",
    "    ('High beta - High theta', 'mediumvioletred'),\n",
    "    ('Normal range', 'black')\n",
    "]\n",
    "\n",
    "# Initialize lists for colors and labels\n",
    "colors = []\n",
    "labels = []\n",
    "\n",
    "# Assign colors and labels based on conditions\n",
    "for theta, beta in zip(a, b):\n",
    "    if beta > 0.68 and theta < -0.68:\n",
    "        colors.append('red')\n",
    "        labels.append('High beta - Low theta')\n",
    "    elif theta > 0.68 and beta < -0.68:\n",
    "        colors.append('purple')\n",
    "        labels.append('High theta - Low beta')\n",
    "    elif beta > 0.68 and -0.68 < theta < 0.68:\n",
    "        colors.append(\"blue\")\n",
    "        labels.append('High beta - Normal theta')\n",
    "    elif -.68 < theta < 0.68 and beta < -0.68:\n",
    "        colors.append(\"orange\")\n",
    "        labels.append('Normal theta - Low beta')\n",
    "    elif -0.68 < beta < 0.68 and theta > 0.68:\n",
    "        colors.append(\"olive\")\n",
    "        labels.append('Normal beta - High theta')\n",
    "    elif -0.68 < beta < 0.68 and theta < -0.68:\n",
    "        colors.append(\"teal\")\n",
    "        labels.append('Normal beta - Low theta')\n",
    "\n",
    "    elif  beta < -0.68 and theta < -0.68:\n",
    "        colors.append(\"pink\")\n",
    "        labels.append('Low beta - Low theta')\n",
    "    elif  beta > 0.68 and theta > 0.68:\n",
    "        colors.append(\"mediumvioletred\")\n",
    "        labels.append('High beta - High theta')\n",
    "    else:\n",
    "        colors.append('black')\n",
    "        labels.append('Normal range')\n",
    "\n",
    "# Create the legend handles in the correct order\n",
    "handles = []\n",
    "for label, color in order:\n",
    "    handles.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10, label=label))\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.scatter(a, b, color=colors)\n",
    "\n",
    "# Add the gray region and lines\n",
    "plt.fill_betweenx(y=[-0.68, 0.68], x1=-0.68, x2=0.68, color='gray', alpha=0.5, label=\"|z| < 0.68\")\n",
    "plt.hlines(y=[-0.68, 0.68], xmin=-0.68, xmax=0.68, colors='black', linestyles='--', linewidth=1.5)\n",
    "plt.vlines(x=[-0.68, 0.68], ymin=-0.68, ymax=0.68, colors='black', linestyles='--', linewidth=1.5)\n",
    "\n",
    "# Set axis ticks\n",
    "ticks = [-3, -0.68, 0, 0.68, 3]\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks)\n",
    "\n",
    "# Labeling\n",
    "plt.xlabel('Theta z-scores', fontsize=16)\n",
    "plt.ylabel('Beta z-scores', fontsize=16)\n",
    "\n",
    "# Style the plot\n",
    "plt.grid(alpha=0.5)\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"left\"].set_visible(False)\n",
    "plt.gca().spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "# Add the legend with the correct order\n",
    "plt.legend(handles=handles, fontsize=13)\n",
    "\n",
    "# Finalize and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"normal_var.png\", dpi=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "def plot_quantile_gauge(current_value, q1, q3, percentile_5, percentile_95, percentile_50, \n",
    "                        title=\"Quantile-Based Gauge\", min_value=0, max_value=1, show_legend=False, bio_name=None, save_path=\"\"):\n",
    "    \"\"\"\n",
    "    Plots a gauge chart based on quantile ranges with a threshold marker for the 0.5 percentile.\n",
    "    \n",
    "    Parameters:\n",
    "    - current_value (float): The current decimal value to display.\n",
    "    - q1 (float): The 25th percentile value as a decimal.\n",
    "    - q3 (float): The 75th percentile value as a decimal.\n",
    "    - percentile_5 (float): The 5th percentile value as a decimal.\n",
    "    - percentile_95 (float): The 95th percentile value as a decimal.\n",
    "    - percentile_50 (float): The 0.5 percentile value as a decimal, marked by a threshold line.\n",
    "    - title (str): The title of the gauge chart.\n",
    "    - min_value (float): The minimum value for the gauge range (default is 0).\n",
    "    - max_value (float): The maximum value for the gauge range (default is 1).\n",
    "    - show_legend (bool): Whether to display the legend with color-coded ranges (default is False).\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    if current_value < percentile_5:\n",
    "        value_color = \"rgba(115, 90, 63, 1)\"  # Purple \n",
    "    elif current_value < q1:\n",
    "        value_color = \"rgba(255, 215, 0, 1)\"  # Gold \n",
    "    elif current_value <= q3:\n",
    "        value_color = \"rgba(34, 139, 34, 1)\"  # Green \n",
    "    elif current_value <= percentile_95:\n",
    "        value_color = \"rgba(255, 99, 71, 1)\"  # Tomato red\n",
    "    else:\n",
    "        value_color = \"rgba(128, 0, 128, 1)\"  # Purple\n",
    "\n",
    "    if show_legend:\n",
    "        number_font_size = 75\n",
    "        delta_font_size = 30\n",
    "    else:\n",
    "        number_font_size = 150\n",
    "        delta_font_size = 50\n",
    "        \n",
    "    fig = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number+delta\",\n",
    "        value=current_value,\n",
    "        number={'font': {'size': number_font_size, 'family': 'Arial', 'color': value_color}},  \n",
    "        delta={'reference': percentile_50, 'position': \"top\", 'font': {'size': delta_font_size}},\n",
    "        gauge={\n",
    "            'axis': {\n",
    "                'range': [min_value, max_value],\n",
    "                'tickfont': {'size': 30, 'family': 'Arial', 'color': 'black'},\n",
    "                'showticklabels': True,\n",
    "                'tickwidth': 2,\n",
    "                'tickcolor': \"lightgrey\",\n",
    "                'tickvals': [round(min_value + i * (max_value - min_value) / 10, 2) for i in range(11)],  \n",
    "            },\n",
    "            'bar': {'color': \"rgb(255, 69, 58)\"},  \n",
    "            'steps': [\n",
    "                {'range': [min_value, percentile_5], 'color': \"rgba(115, 90, 63, 1)\"},  # Purple \n",
    "                {'range': [percentile_5, q1], 'color': \"rgba(255, 215, 0, 0.6)\"},  # Warm gold \n",
    "                {'range': [q1, q3], 'color': \"rgba(34, 139, 34, 0.7)\"},  # Forest green \n",
    "                {'range': [q3, percentile_95], 'color': \"rgba(255, 99, 71, 0.6)\"},  # Soft tomato red\n",
    "                {'range': [percentile_95, max_value], 'color': \"rgba(128, 0, 128, 0.9)\"},  # dark Purple\n",
    "            ],\n",
    "            'threshold': {\n",
    "                'line': {'color': \"black\", 'width': 6},  # Black line for the 0.5th percentile marker\n",
    "                'thickness': 0.75,\n",
    "                'value': percentile_50, \n",
    "            },\n",
    "        },\n",
    "        title={\n",
    "            'text': bio_name,\n",
    "            'font': {'size': 50, 'family': 'Arial', 'color': 'black'}\n",
    "        }\n",
    "    ))\n",
    "\n",
    "    if show_legend:\n",
    "        fig.add_trace(go.Scatter(x=[None], y=[None], mode=\"markers\",\n",
    "                                 marker=dict(size=12, color=\"rgba(115, 90, 63, 1)\"),\n",
    "                                 name=\"0-5th Percentile (Extremely Low)\"))\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=[None], y=[None], mode=\"markers\",\n",
    "                                 marker=dict(size=12, color=\"rgba(255, 215, 0, 0.6)\"),\n",
    "                                 name=\"5th-25th Percentile (Below Normal)\"))\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=[None], y=[None], mode=\"markers\",\n",
    "                                 marker=dict(size=12, color=\"rgba(34, 139, 34, 0.7)\"),\n",
    "                                 name=\"25th-75th Percentile (Normal)\"))\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=[None], y=[None], mode=\"markers\",\n",
    "                                 marker=dict(size=12, color=\"rgba(255, 99, 71, 0.6)\"),\n",
    "                                 name=\"75th-95th Percentile (Above Normal)\"))\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=[None], y=[None], mode=\"markers\",\n",
    "                                 marker=dict(size=12, color=\"rgba(128, 0, 128, 0.9)\"),\n",
    "                                 name=\"95th-100th Percentile (Extremely High)\"))\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Update layout for better aesthetics\n",
    "    fig.update_layout(\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "        margin=dict(t=50, b=100 if show_legend else 30, l=30, r=30),  # Adjust bottom margin for legend\n",
    "        showlegend=show_legend,\n",
    "        width=1100,\n",
    "        height=700,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",      # Horizontal orientation for legend\n",
    "            yanchor=\"top\",        # Align legend to top\n",
    "            y=-0.2,               # Place below the chart\n",
    "            xanchor=\"center\",     # Center legend horizontally\n",
    "            x=0.5,                # Centered under the chart\n",
    "            font=dict(size=14)    # Set font size for readability\n",
    "        ),\n",
    "        xaxis=dict(visible=False),  # Hide x-axis\n",
    "        yaxis=dict(visible=False)   # Hide y-axis   \n",
    "    )\n",
    "\n",
    "    # Display the adapted gauge chart\n",
    "    # fig.show()\n",
    "    # Save the figure as a PNG image with the specified name\n",
    "    fig.write_image(os.path.join(save_path, f\"{bio_name}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INOCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_path = \"/home/meganorm-mznasrabadi/Results/natureArticle_new_pcn_no_scalar/NM/Run_0/hetero_SHASH_bspline/Quantiles_estimate.pkl\"\n",
    "feature = ['Adjusted_Canonical_Relative_PowerTheta_all', \"Adjusted_Canonical_Relative_PowerAlpha_all\", 'Adjusted_Canonical_Relative_PowerBeta_all', \"Adjusted_Canonical_Relative_PowerGamma_all\"]\n",
    "features_list = list(merged_data.columns)[3:]\n",
    "\n",
    "sub_index = \"sub-042\"\n",
    "statistics = cal_stats_for_gauge(q_path, feature, features_list, \n",
    "                                 site_id=merged_data.loc[sub_index][\"site\"], \n",
    "                                 gender_id=merged_data.loc[sub_index][\"sex\"], \n",
    "                                 age=merged_data.loc[sub_index][\"age\"]*100)\n",
    "\n",
    "names = [\"Theta\", \"Alpha\", \"Beta\", \"Gamma\"]\n",
    "\n",
    "\n",
    "for i, name in enumerate(feature):\n",
    "    print(names[i])\n",
    "    if names[i] == \"Gamma\": max_value=0.2\n",
    "    else: max_value=1\n",
    "\n",
    "    plot_quantile_gauge(merged_data.loc[sub_index, name],\n",
    "                        statistics[name][1],\n",
    "                        statistics[name][3],\n",
    "                        statistics[name][0],\n",
    "                        statistics[name][4],\n",
    "                        statistics[name][2],\n",
    "                        title=\"\",\n",
    "                        max_value=max_value,\n",
    "                        show_legend=False,\n",
    "                        bio_name=names[i],\n",
    "                        save_path=\"/home/meganorm-mznasrabadi/MEGaNorm/pics/gauges\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub-PD1674\n",
    "# sub-PD1551\n",
    "# sub-PD1517\n",
    "# sub-MNI0079\n",
    "# sub-PD0512\n",
    "# sub-PD1487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neurooscillochart(data, age_slices, save_path):\n",
    "    \n",
    "    # Age ranges\n",
    "    ages = [f\"{i}-{i+5}\" for i in age_slices]\n",
    "    \n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "    \n",
    "    def plot_gender_data(ax, gender_data, title, legend=True, colors=None):\n",
    "        \n",
    "        means = {k: [item[0] * 100 for item in v] for k, v in gender_data.items()}  \n",
    "        stds = {k: [item[1] * 100 * 1.96 for item in v] for k, v in gender_data.items()}  \n",
    "        \n",
    "        df_means = pd.DataFrame(means, index=ages)\n",
    "        df_stds = pd.DataFrame(stds, index=ages)\n",
    "  \n",
    "        my_cmap = ListedColormap(colors, name=\"my_cmap\")\n",
    "        \n",
    "        bar_plot = df_means.plot(kind='bar', yerr=df_stds, capsize=4, stacked=True, ax=ax, alpha=0.7, \n",
    "                                 colormap=my_cmap)\n",
    "        for p in bar_plot.patches:\n",
    "            width, height = p.get_width(), p.get_height()\n",
    "            x, y = p.get_xy()\n",
    "            bar_plot.text(x + width / 2, \n",
    "                          y + height / 2 + 2, \n",
    "                          f'{height:.0f}%', \n",
    "                          ha='center', \n",
    "                          va='center', fontsize=14)\n",
    "        ax.set_title(title, fontsize=18)\n",
    "        ax.set_xlabel('Age Ranges', fontsize=16)\n",
    "        if legend:\n",
    "            ax.legend(loc='upper right', bbox_to_anchor=(1.1,1))  \n",
    "        else:    \n",
    "            ax.get_legend().remove()\n",
    "            \n",
    "        ax.grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "        ax.grid(False, axis='x')  \n",
    "        ax.tick_params(axis='x', labelsize=14)\n",
    "        ax.set_yticklabels([])  \n",
    "    \n",
    "    plot_gender_data(axes[0], data['Male'], \"Males' Chrono-NeuroOscilloChart\", \n",
    "                     colors= ['lightgrey', 'gray', 'dimgrey', 'lightslategray'])\n",
    "    \n",
    "    plot_gender_data(axes[1], data['Female'], \"Females' Chrono-NeuroOscilloChart\", legend=False, \n",
    "                     colors=['lightgrey', 'gray', 'dimgrey', 'lightslategray'])\n",
    "    \n",
    "    axes[1].set_xlabel('Age Ranges', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(os.path.join(save_path, 'Chrono-NeuroOscilloChart.png'), dpi=600)\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PNOCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculateing Oscilograms\n",
    "\n",
    "gender_ids = {'Male':0, 'Female':1}\n",
    "frequency_band_model_ids = {'Theta':0, 'Alpha':2, 'Beta':4, 'Gamma':6}\n",
    "quantiles_path= os.path.join(processing_dir, 'Quantiles_estimate.pkl')\n",
    "oscilograms, age_slices = calculate_oscilochart(quantiles_path, gender_ids, frequency_band_model_ids)\n",
    "\n",
    "plot_neurooscillochart(oscilograms, age_slices, processing_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot growthchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_growthcharts(processing_dir, idp_indices=list(range(8)), \n",
    "                  idp_names= ['Theta',\n",
    "                            'Theta',\n",
    "                            'Alpha',\n",
    "                            'Alpha',\n",
    "                            'Beta',\n",
    "                            'Beta',\n",
    "                            'Gamma',\n",
    "                            'Gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcntoolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
